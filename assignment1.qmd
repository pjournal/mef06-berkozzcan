---
title: "Assignment 1"
author: "Berk Özcan"
date: today
format: 
  html:
    number-sections: True
editor: visual
---

## About me

Berk Özcan, I've been working as a Senior Data Analyst in Doğuş Teknoloji for almost 2 years. I have 5 years of experience in Analytical departments, before that, I worked as a merchandise planner in several retail companies. One of my biggest aim is after this program, I want to get a promotion to become Analytics Manager. I work with mostly SQL and Python in my current job. With my new skills I believe that I can handle complex problems, also in this field we always have to get to update our knowledge and I could enhance my understanding of data and analytics through my education.

[**My linkedin profile**](https://www.linkedin.com/in/berk-%C3%B6zcan-b6b19a13b)

## useR! 2022 - Tutorials -Introduction to Git and GitHub Tutorial-

[*Here is the link*](https://www.youtube.com/watch?v=U186T7U08sA&list=PL77T87Q0eoJhQDXzG2Viq3uHf5YyJfw0L&index=5)

I preferred to watch an introduction video about Git and GitHub. In this video, we can learn the usage of Git and GitHub, why they are important in our life and some bash codes for administrating the pipeline.

Firstly we should understand the notion of version control. With version control, we can manage changes to projects over time, and also we can track changes to files.

There are several reasons why we are using version control:

1)  Collaboration : Simultaneously work on the same orıject
2)  Tracking : Record the development of a project
3)  Restoring versions : Restore older versions of a file
4)  Back-up : Save your work in a remote repository.

WHY GIT:

-Second generation version control system -Unique approach to tracking changes -Streamlined collaboration -Manages evolution of a project -Fast and lightweight branching -Commit messages provide context -Safe testing and experimentation

WHY GITHUB

-Provides cloud storage for our project -Like dropbox but with better features -It allows us to: *view and review our work* sync with a project \*report issues/bugs -contribute to the project -Great way to promote our skills and interests

Some Git Terms we have to know

*Repository* Commit *Push/Pull* Branch *Pull/Merge request* Issues

With this suggested video also ensures how can we use the tool with bash/shell codes.

## R posts relevant to my interests

### Basic Visualization with R

```{r}

### Histogram

data(airquality)
  
hist(airquality$Temp, main ="La Guardia Airport's\
Maximum Temperature(Daily)",
    xlab ="Temperature(Fahrenheit)",
    xlim = c(50, 125), col ="yellow",
    freq = TRUE)
        

### Box Plot

data(airquality)
  
boxplot(airquality$Wind, main = "Average wind speed\
at La Guardia Airport",
        xlab = "Miles per hour", ylab = "Wind",
        col = "orange", border = "brown",
        horizontal = TRUE, notch = TRUE)



### Scatter Plot

data(airquality)
  
plot(airquality$Ozone, airquality$Month,
     main ="Scatterplot Example",
    xlab ="Ozone Concentration in parts per billion",
    ylab =" Month of observation ", pch = 19)

### Heat Map

# Set seed for reproducibility
# set.seed(110)
  
# Create example data
data <- matrix(rnorm(50, 0, 5), nrow = 5, ncol = 5)
  
# Column names
colnames(data) <- paste0("col", 1:5)
rownames(data) <- paste0("row", 1:5)
  
# Draw a heatmap
heatmap(data)     



```

[*reference for the basic visualization with R*](https://www.geeksforgeeks.org/data-visualization-in-r)

### Logistic Regression in R

Logistic regression is one of the most popular model for classification problems. In this part i examined how can we use this algorithm in R.

For this example, we'll use the Default dataset from the ISLR package. We can use the following code to load and view a summary of the dataset:

```{r}
options(repos="https://cran.rstudio.com" )
install.packages("ISLR")

library("ISLR")

data <- ISLR::Default

summary(data)

```

Next, we'll split the dataset into a training set to train the model on and a testing set to test the model on.

```{r}

#make this example reproducible
set.seed(1)

#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
train <- data[sample, ]
test <- data[!sample, ]   

```

Next, we'll use the glm (general linear model) function and specify family="binomial" so that R fits a logistic regression model to the dataset:

```{r}

#fit logistic regression model

model <- glm(default~student+balance+income, family="binomial", data=train)

#disable scientific notation for model summary
options(scipen=999)

#view model summary
summary(model)

glm(formula = default ~ student + balance + income, family = "binomial", 
    data = train)

```

The coefficients in the output indicate the average change in log odds of defaulting. For example, a one unit increase in balance is associated with an average increase of 0.005988 in the log odds of defaulting.

The p-values in the output also give us an idea of how effective each predictor variable is at predicting the probability of default:

P-value of student status: 0.0843

P-value of balance: \<0.0000

P-value of income: 0.4304

Use the Model to Make Predictions:

```{r}

#define two individuals
new <- data.frame(balance = 1400, income = 2000, student = c("Yes", "No"))

#predict probability of defaulting
predict(model, new, type="response")

```

[*reference for the logistic regression with R*](https://www.statology.org/logistic-regression-in-r/)

### LAG & LEAD R Functions

Firstly we have to install and load dplyr package:

```{r}

install.packages("dplyr")       
library("dplyr")     

```

And giving an example vector as x :

```{r}

x<- 1:10

```

Here is the basic application for lag and lead

```{r}

##Lead :

lead(x)

##Lag :

lag(x)

```

[*reference for the lag and lead functions*](https://statisticsglobe.com/r-lead-lag-functions-dplyr-package)
